---
# E2E test scenario using local dev images and manifests built from the source tree for following providers:
# - cluster-api
# - bootstrap kubeadm
# - control-plane kubeadm
# - metal3

images:
  # Use local dev images built source tree;
  - name: quay.io/metal3-io/cluster-api-provider-metal3:latest
    loadBehavior: mustLoad
  - name: quay.io/metal3-io/baremetal-operator:latest
    loadBehavior: mustLoad
  - name: quay.io/metal3-io/ip-address-manager:latest
    loadBehavior: mustLoad

providers:
- name: cluster-api
  type: CoreProvider
  versions:
  - name: ${CAPI_FROM_RELEASE}
    value: "https://github.com/kubernetes-sigs/cluster-api/releases/download/${CAPI_FROM_RELEASE}/core-components.yaml"
    type: "url"
    contract: ${CONTRACT_FROM}
    replacements:
      - old: --metrics-addr=127.0.0.1:8080
        new: --metrics-addr=:8080
    files:
      - sourcePath: "../data/shared/${CAPI_FROM_RELEASE:0:4}/metadata.yaml"
  - name: ${CAPI_TO_RELEASE}
    # Use manifest from source files
    value: "https://github.com/kubernetes-sigs/cluster-api/releases/download/${CAPI_TO_RELEASE}/core-components.yaml"
    type: "url"
    contract: ${CONTRACT_TO}
    files:
      - sourcePath: "../data/shared/${CAPI_TO_RELEASE:0:4}/metadata.yaml"
    replacements:
      - old: "--leader-elect"
        new: "--leader-elect=false"
- name: kubeadm
  type: BootstrapProvider
  versions:
  - name: ${CAPI_FROM_RELEASE} # latest published release in the v1alpha4 series; this is used for v1alpha4 --> v1beta1 clusterctl upgrades test only.
    value: "https://github.com/kubernetes-sigs/cluster-api/releases/download/${CAPI_FROM_RELEASE}/bootstrap-components.yaml"
    type: "url"
    contract: ${CONTRACT_FROM}
    replacements:
      - old: --metrics-addr=127.0.0.1:8080
        new: --metrics-addr=:8080
    files:
      - sourcePath: "../data/shared/${CAPI_FROM_RELEASE:0:4}/metadata.yaml"
  - name: ${CAPI_TO_RELEASE}
    # Use manifest from source files
    value: "https://github.com/kubernetes-sigs/cluster-api/releases/download/${CAPI_TO_RELEASE}/bootstrap-components.yaml"
    type: "url"
    contract: ${CONTRACT_TO}
    files:
      - sourcePath: "../data/shared/${CAPI_TO_RELEASE:0:4}/metadata.yaml"
    replacements:
      - old: "--leader-elect"
        new: "--leader-elect=false"
- name: kubeadm
  type: ControlPlaneProvider
  versions:
  - name: ${CAPI_FROM_RELEASE} # latest published release in the v1alpha4 series; this is used for v1alpha4 --> v1beta1 clusterctl upgrades test only.
    value: "https://github.com/kubernetes-sigs/cluster-api/releases/download/${CAPI_FROM_RELEASE}/control-plane-components.yaml"
    type: "url"
    contract: ${CONTRACT_FROM}
    replacements:
      - old: --metrics-addr=127.0.0.1:8080
        new: --metrics-addr=:8080
    files:
      - sourcePath: "../data/shared/${CAPI_FROM_RELEASE:0:4}/metadata.yaml"
  - name: ${CAPI_TO_RELEASE}
    # Use manifest from source files
    value: "https://github.com/kubernetes-sigs/cluster-api/releases/download/${CAPI_TO_RELEASE}/control-plane-components.yaml"
    type: "url"
    contract: ${CONTRACT_TO}
    files:
      - sourcePath: "../data/shared/${CAPI_TO_RELEASE:0:4}/metadata.yaml"
    replacements:
      - old: "--leader-elect"
        new: "--leader-elect=false"
- name: metal3
  type: InfrastructureProvider
  versions:
  - name: ${CAPM3_FROM_RELEASE}
    value: "https://github.com/metal3-io/cluster-api-provider-metal3/releases/download/${CAPM3_FROM_RELEASE}/infrastructure-components.yaml"
    type: "url"
    contract: ${CONTRACT_FROM}
    files:
    - sourcePath: "../data/infrastructure-metal3/${CAPM3_FROM_RELEASE:0:4}/metadata.yaml"
      targetName: "metadata.yaml"
    - sourcePath: "../_out/cluster-template-ubuntu.yaml"
      targetName: "cluster-template-ubuntu.yaml"
    - sourcePath: "../_out/cluster-template-upgrade-workload.yaml"
      targetName: "cluster-template-upgrade-workload.yaml"
  - name: v1.6.99
    value: "${PWD}/config/default"
    files:
    - sourcePath: "../data/infrastructure-metal3/main/metadata.yaml"
      targetName: "metadata.yaml"
    - sourcePath: "../_out/cluster-template-ubuntu.yaml"
      targetName: "cluster-template-ubuntu.yaml"
    - sourcePath: "../_out/cluster-template-centos.yaml"
      targetName: "cluster-template-centos.yaml"

variables:
  CNI: "/tmp/calico.yaml"
  KUBERNETES_VERSION: "v1.28.1"
  # INIT_WITH_KUBERNETES_VERSION will be used here
  # https://github.com/kubernetes-sigs/cluster-api/blob/bb377163f141d69b7a61479756ee96891f6670bd/test/e2e/clusterctl_upgrade.go#L170
  # INIT_WITH_KUBERNETES_VERSION  used by management cluster upgrade
  INIT_WITH_KUBERNETES_VERSION: "${INIT_WITH_KUBERNETES_VERSION}"
  CONTROL_PLANE_MACHINE_COUNT: 3
  WORKER_MACHINE_COUNT: 1
  APIVersion: "infrastructure.cluster.x-k8s.io/${CAPM3_VERSION}"
  IRONIC_NAMESPACE: "baremetal-operator-system"
  NAMEPREFIX: "baremetal-operator"
  IRONIC_DATA_DIR: "${DEV_ENV_WORKING_DIR}/ironic"
  BMOPATH: "${M3PATH}/baremetal-operator"
  IRONIC_TLS_SETUP: "true"
  IRONIC_BASIC_AUTH: "true"
  IRONIC_KEEPALIVED: "true"
  IRONIC_USE_MARIADB: "false"
  RESTART_CONTAINER_CERTIFICATE_UPDATED: "true"
  CONTAINER_REGISTRY: "${CONTAINER_REGISTRY:-quay.io}"
  DOCKER_HUB_PROXY: "${DOCKER_HUB_PROXY:-docker.io}"
  IRONIC_IMAGE_TAG: "${IRONIC_IMAGE_TAG:-main}"
  UPGRADED_BMO_IMAGE_TAG: "${UPGRADED_BMO_IMAGE_TAG:-main}"

  INIT_WITH_BINARY: "https://github.com/kubernetes-sigs/cluster-api/releases/download/${CAPI_FROM_RELEASE}/clusterctl-{OS}-{ARCH}"
  PROVIDER_ID_FORMAT: "metal3://{{ ds.meta_data.providerid }}"
  # Pin Calico version
  CALICO_PATCH_RELEASE: "v3.25.1"
  # Pin CertManager for upgrade tests
  CERT_MANAGER_RELEASE: v1.12.3
  # Default vars for the template, those values could be overridden by the env-vars.
  CAPI_VERSION: "v1beta1"
  CAPM3_VERSION: "v1beta1"
  CONFIG_FILE_PATH: "${CAPI_CONFIG_FOLDER}/clusterctl.yaml"
  SERVICE_CIDR: "10.96.0.0/12"
  POD_CIDR: "192.168.0.0/18"
  BARE_METAL_PROVISIONER_CIDR: "24"
  CLUSTER_APIENDPOINT_HOST: "192.168.111.249"
  CLUSTER_APIENDPOINT_PORT: "6443"
  EXTERNAL_SUBNET_V4_PREFIX: "24"
  CLUSTER_PROVISIONING_INTERFACE: "ironicendpoint"
  IPAM_EXTERNALV4_POOL_RANGE_START: "192.168.111.100"
  IPAM_EXTERNALV4_POOL_RANGE_END: "192.168.111.200"
  IPAM_PROVISIONING_POOL_RANGE_START: "172.22.0.100"
  IPAM_PROVISIONING_POOL_RANGE_END: "172.22.0.200"
  EXTERNAL_SUBNET_V4_HOST: "192.168.111.1"
  REGISTRY: "192.168.111.1:5000"
  IMAGE_CHECKSUM_TYPE: "sha256"
  IMAGE_USERNAME: "metal3"
  NODE_DRAIN_TIMEOUT: "0s"

intervals:
  default/wait-controllers: ["5m", "10s"]
  default/wait-cluster: ["20m", "30s"] # The second time to check the availibility of the cluster should happen late, so kcp object has time to be created
  default/wait-control-plane: ["30m", "10s"]
  default/wait-worker-nodes: ["30m", "10s"]
  default/wait-delete-cluster: ["20m", "10s"]
  default/wait-machine-upgrade: ["50m", "10s"]
  default/wait-machine-remediation: ["30m", "10s"]
  default/wait-vm-state: ["20m", "100ms"]
  default/monitor-vm-state: ["1m", "500ms"]
  default/monitor-provisioning: ["5m", "500ms"]
  default/wait-deployment: ["10m", "10s"]
  default/wait-job: ["10m", "10s"]
  default/wait-service: ["10m", "10s"]
  default/wait-object-provisioned: ["10m", "10s"]
  default/wait-cp-available: ["50m", "30s"]
  default/wait-bmh-deprovisioning: ["50m", "10s"]
  default/wait-bmh-available: ["50m", "20s"]
  default/wait-bmh-inspecting: ["10m", "2s"]
  default/wait-machine-deleting: ["15m", "2s"]
  default/wait-bmh-deprovisioning-available: ["7m", "500ms"]
  default/wait-bmh-available-provisioning: ["15m", "2s"]
  default/wait-machine-running: ["50m", "20s"]
  default/wait-bmh-provisioned: ["50m", "20s"]
  default/wait-pod-restart: ["6m", "10s"]
  default/wait-deprovision-cluster: ["30m", "10s"]
  default/wait-all-pod-to-be-running-on-target-cluster: ["15m", "10s"]
